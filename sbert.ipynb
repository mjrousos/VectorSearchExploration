{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers (SBERT, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas document vectors with TF-IDF or BM25 are sparse and high-dimensional, [SBERT (Sentence-BERT)](https://www.sbert.net/) and other sentence transformers produce dense, low-dimensional representation of text. SBERT is built on the BERT pre-trained transformer network. Unlike TF-IDF, sentence transformers preserves semantic meaning (so \"puppy\" and \"dog\" are similar when vectorized). TF-IDF and BM25 are purely token based. SBERT is a pre-trained model that converts text into a 768-dimensional vector. This notebook demonstrates how to use sentence transformers to compute the similarity between two texts.\n",
    "\n",
    "Unlike TF-IDF and BM25, sentence transformers use pre-trained models so we can't build them from scratch without any dependencies. Instead, we'll use the `sentence-transformers` library, which provides a simple interface for encoding with these models. Sentence-transformers is built on top of Hugging Face transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Available models: https://www.sbert.net/docs/pretrained_models.html\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "# model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "# model = SentenceTransformer('multi-qa-distilbert-cos-v1')\n",
    "# model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus of documents to search\n",
    "import os\n",
    "\n",
    "directory = \".\\plays\"\n",
    "files = {}\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            file_name = os.path.splitext(filename)[0]\n",
    "            file_contents = file.read()\n",
    "            files[file_name] = file_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating embeddings is *significantly* faster than vectorizing with sparse vector algorithms. Compared to minutes to generate TF-IDF or BM25 vectors, SBERT can generate embeddings in seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings = model.encode(list(files.values()))\n",
    "print(corpus_embeddings[:5])\n",
    "print(corpus_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity (vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    return dot_product / (norm_vector1 * norm_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_document_relevance(query):\n",
    "    class Relevance:\n",
    "        def __init__(self, name, similarity):\n",
    "            self.name = name\n",
    "            self.similarity = similarity\n",
    "\n",
    "    query_embedding = model.encode(query)\n",
    "\n",
    "    print(f'Relevance for \"{query}\":')\n",
    "    print('--------------')\n",
    "\n",
    "    doc_names = list(files.keys())\n",
    "    top_answers = [Relevance(doc_names[i], cosine_similarity(query_embedding, corpus_embeddings[i])) for i in range(len(files))]\n",
    "    top_answers.sort(key=lambda x: x.similarity, reverse=True)\n",
    "    for answer in top_answers[:5]:\n",
    "        print(f'{answer.name}: {answer.similarity}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_document_relevance(\"Which play has three witches?\")\n",
    "check_document_relevance(\"Which play has a friar as an important character?\")\n",
    "check_document_relevance(\"Which play has a character named Caesar?\")\n",
    "check_document_relevance(\"Caesar?\")\n",
    "check_document_relevance(\"Which play is set in Denmark?\")\n",
    "check_document_relevance(\n",
    "\"To be or not to be—that is the question \\\n",
    "Whether ’tis nobler in the mind to suffer \\\n",
    "The slings and arrows of outrageous fortune, \\\n",
    "Or to take arms against a sea of troubles \\\n",
    "And, by opposing, end them. To die, to sleep— \\\n",
    "No more—and by a sleep to say we end \\\n",
    "The heartache and the thousand natural shocks \\\n",
    "That flesh is heir to—’tis a consummation \\\n",
    "Devoutly to be wished. To die, to sleep— \\\n",
    "To sleep, perchance to dream. Ay, there’s the rub, \\\n",
    "For in that sleep of death what dreams may come, \\\n",
    "When we have shuffled off this mortal coil, \\\n",
    "Must give us pause.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does ok (though apparently it hasn't read Hamlet!), but SBERT is really meant for sentence or paragraph level similarity. So, asking questions about a much larger document isn't its intended use case. Curiously, TF-IDF is the best performing 'which document talks about X' algorithm even though it is lacking many of the more advanced features (semanticically-aware dense vectors, etc.) of SBERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "Lets try chunking the text into smaller pieces and see if we can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semchunk\n",
    "import tiktoken\n",
    "\n",
    "class Chunk:\n",
    "    def __init__(self, text, doc_name, embedding):\n",
    "        self.text = text\n",
    "        self.doc_name = doc_name\n",
    "        self.embedding = embedding\n",
    "\n",
    "# Chunk the files into smaller portions\n",
    "corpus_scenes = {}\n",
    "corpus_chunks = {}\n",
    "doc_names = list(files.keys())\n",
    "encoder = tiktoken.encoding_for_model('gpt-4')\n",
    "\n",
    "print(\"Chunking plays...\")\n",
    "for play, text in files.items():\n",
    "    corpus_scenes[play] = [Chunk(t, play, None) for t in text.split('SCENE ') if len(t) > 10]\n",
    "    corpus_chunks[play] = [Chunk(t, play, None) for t in semchunk.chunk(text, chunk_size = 512, token_counter=lambda text: len(encoder.encode(text)))]\n",
    "\n",
    "print(\"Embedding chunks...\")\n",
    "for play in doc_names:\n",
    "    for chunk in corpus_scenes[play]:\n",
    "        chunk.embedding = model.encode(chunk.text)\n",
    "    for chunk in corpus_chunks[play]:\n",
    "        chunk.embedding = model.encode(chunk.text)\n",
    "\n",
    "print(\"Complete\")\n",
    "\n",
    "for play in doc_names:\n",
    "    print(f'{play}: {len(corpus_scenes[play])} scenes, {len(corpus_chunks[play])} chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_document_relevance(query, chunks):\n",
    "    class Relevance:\n",
    "        def __init__(self, name, snippet, similarity):\n",
    "            self.name = name\n",
    "            self.snippet = snippet\n",
    "            self.similarity = similarity\n",
    "\n",
    "    query_embedding = model.encode(query)\n",
    "\n",
    "    print(f'Relevance for \"{query}\":')\n",
    "    print('--------------')\n",
    "\n",
    "    relevances = []\n",
    "    for play in chunks:\n",
    "        for chunk in play:\n",
    "            similarity = cosine_similarity(query_embedding, chunk.embedding)\n",
    "            relevances.append(Relevance(chunk.doc_name, chunk.text, similarity))\n",
    "    relevances.sort(key=lambda x: x.similarity, reverse=True)\n",
    "    for answer in relevances[:3]:\n",
    "        print(f'{answer.name} ({answer.similarity}): {answer.snippet[:500]}\\n')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_document_relevance(\"Which play has three witches?\", corpus_chunks.values())\n",
    "check_document_relevance(\"Which play has a friar as an important character?\", corpus_chunks.values())\n",
    "check_document_relevance(\"Which play has a character named Caesar?\", corpus_chunks.values())\n",
    "check_document_relevance(\"Which play is set in Denmark?\", corpus_chunks.values())\n",
    "check_document_relevance(\"Who was Juliet's lover?\", corpus_chunks.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_document_relevance(\"Which play has three witches?\", corpus_scenes.values())\n",
    "check_document_relevance(\"Which play has a friar as an important character?\", corpus_scenes.values())\n",
    "check_document_relevance(\"Which play has a character named Caesar?\", corpus_scenes.values())\n",
    "check_document_relevance(\"Which play is set in Denmark?\", corpus_scenes.values())\n",
    "check_document_relevance(\"Who was Juliet's lover?\", corpus_scenes.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking worked much better. We could even refine things further by seeing how many different chunks in a given play have high relevance with the query and then use that to determine the most relevant play."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

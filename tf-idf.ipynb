{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "[TF-IDF (Term Frequency-Inverse Document Frequency)](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.\n",
    "\n",
    "TF is the frequency of a word in a document. It is calculated as the number of times a word appears in a document, divided by the total number of words in that document.\n",
    "\n",
    "IDF is the inverse of the document frequency among the whole corpus of documents. It is calculated as the logarithm of the number of documents in the corpus divided by the number of documents where the specific term appears. IDF increases as the term appears in fewer documents. If a term appears in all documents, then IDF is 0 because it's ubiquitous and no document matters more than others.\n",
    "\n",
    "TF-IDF is simply the product of TF and IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus of documents to search\n",
    "import string\n",
    "\n",
    "a = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way — in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\"\n",
    "b = \"Once upon a midnight dreary, as I pondered weak and weary,\\nOver many a quaint and curious volume of forgotten lore\\nWhile I nodded, nearly napping, suddenly there came a tapping,\\nAs of someone gently rapping, rapping at my chamber door.\"\n",
    "c = \"Call me Ishmael. Some years ago — never mind how long precisely — having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world. It is a way I have of driving off the spleen, and regulating the circulation. Whenever I find myself growing grim about the mouth; whenever it is a damp, drizzly November in my soul; whenever I find myself involuntarily pausing before coffin warehouses, and bringing up the rear of every funeral I meet; and especially whenever my hypos get such an upper hand of me, that it requires a strong moral principle to prevent me from deliberately stepping into the street, and methodically knocking people’s hats off — then, I account it high time to get to sea as soon as I can. This is my substitute for pistol and ball. With a philosophical flourish Cato throws himself upon his sword; I quietly take to the ship. There is nothing surprising in this. If they but knew it, almost all men in their degree, some time or other, cherish very nearly the same feelings towards the ocean with me.\"\n",
    "d = \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or eat: it was a hobbit-hole, and that means comfort.\"\n",
    "e = \"In the late summer of that year we lived in a house in a village that looked across the river and the plain to the mountains. In the bed of the river there were pebbles and boulders, dry and white in the sun, and the water was clear and swiftly moving and blue in the channels. Troops went by the house and down the road and the dust they raised powdered the leaves of the trees. The trunks of the trees too were dusty and the leaves fell early that year and we saw the troops marching along the road and the dust rising and leaves, stirred by the breeze, falling and the soldiers marching and afterward the road bare and white except for the leaves.\"\n",
    "f = \"You don't know about me without you have read a book by the name of The Adventures of Tom Sawyer; but that ain't no matter. That book was made by Mr. Mark Twain, and he told the truth, mainly. There was things which he stretched, but mainly he told the truth. That is nothing. I never seen anybody but lied one time or another, without it was Aunt Polly, or the widow, or maybe Mary. Aunt Polly - Tom's Aunt Polly, she is - and Mary, and the Widow Douglas is all told about in that book, which is mostly a true book, with some stretchers, as I said before.\"\n",
    "g = \"It was a bright cold day in April, and the clocks were striking thirteen.\"\n",
    "h = \"Squire Trelawnay, Dr Livesey, and the rest of these gentlemen having asked me to write down the whole particulars about Treasure Island, from the beginning to the end, keeping nothing back but the bearings of the island, and that only because there is still treasure not yet lifted, I take up my pen in the year of grace 17 — and go back to the time when my father kept the Admiral Benbow inn and the brown old seaman with the sabre cut first took up his lodging under our roof.\"\n",
    "i = \"When Mr. Bilbo Baggins of Bag End announced that he would shortly be celebrating his eleventy-first birthday with a party of special magnificence, there was much talk and excitement in Hobbiton.\"\n",
    "j = \"Two households, both alike in dignity\\n(In fair Verona, where we lay our scene),\\nFrom ancient grudge break to new mutiny,\\nWhere civil blood makes civil hands unclean.\\nFrom forth the fatal loins of these two foes\\nA pair of star-crossed lovers take their life;\\nWhose misadventured piteous overthrows\\nDoth with their death bury their parents’ strife.\\nThe fearful passage of their death-marked love\\nAnd the continuance of their parents’ rage,\\nWhich, but their children’s end, naught could remove,\\nIs now the two hours’ traffic of our stage;\\nThe which, if you with patient ears attend,\\nWhat here shall miss, our toil shall strive to mend.\"\n",
    "\n",
    "sample_docs = [[term.lower().translate(str.maketrans('', '', string.punctuation)) for term in doc.split()] for doc in [a, b, c, d, e, f, g, h, i, j]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Frequency of term in document / total number of terms in document\n",
    "def tf(term, doc):\n",
    "    return doc.count(term) / len(doc)\n",
    "\n",
    "# Log of total number of documents / number of documents with term\n",
    "def idf(term, corpus):\n",
    "    docs_with_term = sum([1 for doc in corpus if term in doc])\n",
    "    if docs_with_term == 0:\n",
    "        return 0\n",
    "    return np.log10(len(corpus) / docs_with_term)\n",
    "\n",
    "# Product of tf and idf\n",
    "def tfidf(term, doc, corpus):\n",
    "    # Check TF first since if the term doesn't appear in *any* doc, we\n",
    "    # can't calculate the IDF and should just return 0.\n",
    "    term = term.lower()\n",
    "    if (tf(term, doc) == 0):\n",
    "        return 0\n",
    "    return tf(term, doc) * idf(term, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([tfidf(\"it\", doc, sample_docs) for doc in sample_docs])\n",
    "print([tfidf(\"Ishmael\", doc, sample_docs) for doc in sample_docs])\n",
    "print([tfidf(\"hobbit\", doc, sample_docs) for doc in sample_docs])\n",
    "print([tfidf(\"some\", doc, sample_docs) for doc in sample_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to create a vector of TF-IDF values for each document in a corpus. This is done by calculating the TF-IDF values for each word in the corpus for that document. This is what `TfidfVectorizer` from the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set from the combination of all the documents\n",
    "vocab = set([term for doc in sample_docs for term in doc])\n",
    "\n",
    "def tfidfVectorizer(doc, vocab, corpus):\n",
    "    ret = []\n",
    "    for word in vocab:\n",
    "        ret.append(tfidf(word, doc, corpus))\n",
    "    return ret\n",
    "\n",
    "for doc in sample_docs:\n",
    "    print(tfidfVectorizer(doc, vocab, sample_docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a larger data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = \".\\plays\"\n",
    "files = {}\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            file_name = os.path.splitext(filename)[0]\n",
    "            file_contents = file.read().lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "            files[file_name] = file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab = set([term for doc in files.values() for term in doc])\n",
    "len(full_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that vectorizing large documents with a large vocabulary is slow. On my laptop, it takes 30+ seconds per play to vectorize the 37 plays in the Shakespeare corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for file in files:\n",
    "    print(f'Vectorizing {file}... {len(vectors)}/{len(files)}')\n",
    "    vectors[file] = tfidfVectorizer(files[file], full_vocab, files.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the TF-IDF values for some words in these documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tf_idf(word):\n",
    "    word = word.lower()\n",
    "    print(f'TF-IDF for \"{word}\":')\n",
    "    print('--------------')\n",
    "    for file in vectors:\n",
    "        if word in full_vocab:\n",
    "            print(f'{file}: {vectors[file][list(full_vocab).index(word)]}')\n",
    "        else:\n",
    "            print(f'{file}: 0')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_tf_idf(\"macbeth\")\n",
    "# check_tf_idf(\"the\")\n",
    "# check_tf_idf(\"friar\")\n",
    "# check_tf_idf(\"caesar\")\n",
    "# check_tf_idf(\"juliet\")\n",
    "# check_tf_idf(\"poison\")\n",
    "check_tf_idf(\"witch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also see what happens if we construct vectors for questions and compare them using cosine similarity. This is not semantic search, but it should be able to identify the relevant terms in the query and match them with appropriate documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity (vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    return dot_product / (norm_vector1 * norm_vector2)\n",
    "\n",
    "def check_document_relevance(query):\n",
    "    class Relevance:\n",
    "        def __init__(self, name, similarity):\n",
    "            self.name = name\n",
    "            self.similarity = similarity\n",
    "\n",
    "    query_tokens = query.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    query_vector = tfidfVectorizer(query_tokens, full_vocab, files.values())\n",
    "    print(f'Cosine Similarity for \"{query}\":')\n",
    "    print('--------------')\n",
    "    top_answers = [Relevance(name, cosine_similarity(query_vector, vectors[name])) for name in vectors]\n",
    "    top_answers.sort(key=lambda x: x.similarity, reverse=True)\n",
    "    for answer in top_answers[:5]:\n",
    "        print(f'{answer.name}: {answer.similarity}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_document_relevance(\"Which play has three witches?\")\n",
    "check_document_relevance(\"Which play has a friar as an important character?\")\n",
    "check_document_relevance(\"Which play has a character named Caesar?\")\n",
    "check_document_relevance(\"Which play is set in Denmark?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
